# ConvAI - Smart Memory Chat App

> AI chat that remembers and understands conversation context using vector embeddings and semantic search.

ðŸ”— **[Live Demo](https://conv-ai-six.vercel.app)** | ðŸš€ **[Backend API](https://convai-production.up.railway.app)**

## Key Features

- **Intelligent Memory**: Finds relevant past conversations by meaning, not keywords
- **Fast Responses**: Background memory storage, ~3 second response time
- **Privacy**: User isolation with GDPR-compliant data deletion
- **Semantic Search**: "chocolate cookies" matches "baking desserts"

## Tech Stack

**Backend**: FastAPI â€¢ OpenAI GPT-3.5 â€¢ Pinecone Vector DB â€¢ LangChain  
**Frontend**: React â€¢ Vite â€¢ Tailwind CSS  
**Deploy**: Railway â€¢ Vercel

## Quick Start

### Backend
```bash
cd Backend
python -m venv venv && venv\Scripts\activate
pip install -r requirements.txt
# Add OPENAI_API_KEY and PINECONE_API_KEY to .env
python run.py
```

### Frontend
```bash
cd frontend
npm install && npm run dev
```

## How Smart Memory Works

1. **Store**: Conversations â†’ Vector embeddings â†’ Pinecone
2. **Search**: New message â†’ Find similar past conversations
3. **Context**: Recent chat + Relevant history â†’ OpenAI
4. **Result**: Context-aware AI responses

## What This Demonstrates

- **Vector Database Implementation** with semantic search
- **Production AI Architecture** with background processing  
- **Modern Full-Stack Development** with proper deployment
- **Advanced Memory Systems** combining short-term + long-term storage

## ðŸ”§ Environment Variables

```bash
OPENAI_API_KEY=sk-your-key-here
PINECONE_API_KEY=your-key-here
```
